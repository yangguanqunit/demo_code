{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de04a777-2fea-4e22-83e9-bfe03e8d4754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461e62bb-1c9d-42e9-904a-0d448a98c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d6785d-1905-4074-990f-47a20c0e6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(input, target):\n",
    "    # loss = F.cross_entropy(input, target)\n",
    "    loss = F.nll_loss(input, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a9b0be-8545-4581-884e-ccfbfde98c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(288, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = nn.AvgPool2d(2, stride=2)(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)), inplace=True)\n",
    "        x = nn.AvgPool2d(2, stride=2)(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)), inplace=True)\n",
    "        x = nn.AvgPool2d(2, stride=2)(x)\n",
    "        x = x.flatten(1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.fc1 = nn.Linear(784,512)\n",
    "#         self.fc2 = nn.Linear(512,256)\n",
    "#         self.fc3 = nn.Linear(256,128)\n",
    "#         self.fc4 = nn.Linear(128,10)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1,784)\n",
    "#         x = F.relu(nn.LayerNorm(512)(self.fc1(x)))\n",
    "#         x = F.relu(nn.LayerNorm(256)(self.fc2(x)))\n",
    "#         x = F.relu(nn.LayerNorm(128)(self.fc3(x)))\n",
    "#         x = self.fc4(x)\n",
    "#         return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e2a62-3be0-4904-a957-fe6b2cb9d82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a44d14-0d94-4978-a82b-1fee2649c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms, Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774dd8e6-cde0-45e7-87a0-afbf3f216a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mnist (/home/ygq/.cache/huggingface/datasets/mnist/mnist/1.0.0/fda16c03c4ecfb13f165ba7e29cf38129ce035011519968cdaf74894ce91c9d4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad47433cd5d4a9b8d52342e5a04e17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "])\n",
    "\n",
    "dataset = load_dataset(\"mnist\")\n",
    "\n",
    "def transform_(examples):\n",
    "    examples['pixel_values'] = [transform(image.convert('L')) for image in examples['image']]\n",
    "    del examples['image']\n",
    "    return examples\n",
    "\n",
    "dataset_with_transformed = dataset.with_transform(transform_)\n",
    "train_data_loader = DataLoader(dataset_with_transformed['train'], batch_size=256, shuffle=True)\n",
    "test_data_loader = DataLoader(dataset_with_transformed['test'], batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c724ba11-42d0-472e-bbb4-c2d4a449e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "trainsform_ = Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "    ])\n",
    "\n",
    "def get_train_dataloader():\n",
    "    dataset = datasets.MNIST(root='../data/', train=True, transform=trainsform_, download=True)\n",
    "    train_data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    return train_data_loader\n",
    "\n",
    "def get_test_dataloader():\n",
    "    dataset = datasets.MNIST(root='../data/', train=False, transform=trainsform_, download=True)\n",
    "    test_data_loader = DataLoader(dataset, batch_size=1000, shuffle=False)\n",
    "    return test_data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bcddac7-b111-464d-b53c-aeccc7f47311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epoch, model):\n",
    "    model.train()\n",
    "    train_data_loader = get_train_dataloader()\n",
    "    print(\"Our model is training...\")\n",
    "    for batch_idx, (data, target) in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # data = batch['pixel_values'].to(device)\n",
    "        # target = batch['label'].to(device)\n",
    "        predict = model(data.cuda())\n",
    "        loss = calculate_loss(predict, target.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"epoch {epoch}, batch_idx {batch_idx}, loss is {loss.item()}\")\n",
    "            \n",
    "            \n",
    "@torch.no_grad()\n",
    "def test_loop(epoch, model):\n",
    "    model.eval()\n",
    "    test_data_loader = get_test_dataloader()\n",
    "    print(\"Our model is testing...\")\n",
    "    counts = 0\n",
    "    correct_counts = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_data_loader):\n",
    "        # data = batch['pixel_values'].to(device)\n",
    "        # target = batch['label'].to(device)\n",
    "        predict = torch.argmax(model(data.cuda()), dim=1)\n",
    "        counts += data.shape[0]\n",
    "        correct_counts += sum(torch.where(predict == target.cuda(), 1, 0)).item()\n",
    "    print(f\"{epoch} accuracy is {correct_counts / counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "406455a3-6c53-4e31-8a1d-499de23fae2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model is training...\n",
      "epoch 0, batch_idx 0, loss is -0.09854584187269211\n",
      "epoch 0, batch_idx 100, loss is -0.15113712847232819\n",
      "epoch 0, batch_idx 200, loss is -0.3827395737171173\n",
      "epoch 0, batch_idx 300, loss is -0.5021599531173706\n",
      "epoch 0, batch_idx 400, loss is -0.6136916875839233\n",
      "epoch 0, batch_idx 500, loss is -0.60197913646698\n",
      "epoch 0, batch_idx 600, loss is -0.6772567629814148\n",
      "epoch 0, batch_idx 700, loss is -0.7940143346786499\n",
      "epoch 0, batch_idx 800, loss is -0.817430853843689\n",
      "epoch 0, batch_idx 900, loss is -0.7458800673484802\n",
      "epoch 0, batch_idx 1000, loss is -0.9080413579940796\n",
      "epoch 0, batch_idx 1100, loss is -0.8226488828659058\n",
      "epoch 0, batch_idx 1200, loss is -0.8863486051559448\n",
      "epoch 0, batch_idx 1300, loss is -0.8287241458892822\n",
      "epoch 0, batch_idx 1400, loss is -0.9047046303749084\n",
      "epoch 0, batch_idx 1500, loss is -0.8200705051422119\n",
      "epoch 0, batch_idx 1600, loss is -0.8367782235145569\n",
      "epoch 0, batch_idx 1700, loss is -0.9089874625205994\n",
      "epoch 0, batch_idx 1800, loss is -0.8985351920127869\n",
      "Our model is testing...\n",
      "0 accuracy is 0.8768\n",
      "Our model is training...\n",
      "epoch 1, batch_idx 0, loss is -0.8514227867126465\n",
      "epoch 1, batch_idx 100, loss is -0.8658679723739624\n",
      "epoch 1, batch_idx 200, loss is -0.9528487324714661\n",
      "epoch 1, batch_idx 300, loss is -0.9173651337623596\n",
      "epoch 1, batch_idx 400, loss is -0.9506531357765198\n",
      "epoch 1, batch_idx 500, loss is -0.8833151459693909\n",
      "epoch 1, batch_idx 600, loss is -0.9866656064987183\n",
      "epoch 1, batch_idx 700, loss is -0.9141573905944824\n",
      "epoch 1, batch_idx 800, loss is -0.9757812023162842\n",
      "epoch 1, batch_idx 900, loss is -0.9516872763633728\n",
      "epoch 1, batch_idx 1000, loss is -0.9621251225471497\n",
      "epoch 1, batch_idx 1100, loss is -0.950295627117157\n",
      "epoch 1, batch_idx 1200, loss is -0.9559996724128723\n",
      "epoch 1, batch_idx 1300, loss is -0.9810003638267517\n",
      "epoch 1, batch_idx 1400, loss is -0.9255979061126709\n",
      "epoch 1, batch_idx 1500, loss is -0.9627611041069031\n",
      "epoch 1, batch_idx 1600, loss is -0.997852087020874\n",
      "epoch 1, batch_idx 1700, loss is -0.8789664506912231\n",
      "epoch 1, batch_idx 1800, loss is -0.971297562122345\n",
      "Our model is testing...\n",
      "1 accuracy is 0.9771\n",
      "Our model is training...\n",
      "epoch 2, batch_idx 0, loss is -0.9626872539520264\n",
      "epoch 2, batch_idx 100, loss is -0.9905660152435303\n",
      "epoch 2, batch_idx 200, loss is -0.9641459584236145\n",
      "epoch 2, batch_idx 300, loss is -0.9136171340942383\n",
      "epoch 2, batch_idx 400, loss is -0.9946639537811279\n",
      "epoch 2, batch_idx 500, loss is -0.9876673221588135\n",
      "epoch 2, batch_idx 600, loss is -0.9619663953781128\n",
      "epoch 2, batch_idx 700, loss is -0.9887417554855347\n",
      "epoch 2, batch_idx 800, loss is -0.9722625017166138\n",
      "epoch 2, batch_idx 900, loss is -0.9734240174293518\n",
      "epoch 2, batch_idx 1000, loss is -0.9929085969924927\n",
      "epoch 2, batch_idx 1100, loss is -0.9985169768333435\n",
      "epoch 2, batch_idx 1200, loss is -0.9858747720718384\n",
      "epoch 2, batch_idx 1300, loss is -0.9977439045906067\n",
      "epoch 2, batch_idx 1400, loss is -0.9747429490089417\n",
      "epoch 2, batch_idx 1500, loss is -0.9971333742141724\n",
      "epoch 2, batch_idx 1600, loss is -0.994077742099762\n",
      "epoch 2, batch_idx 1700, loss is -0.9831053018569946\n",
      "epoch 2, batch_idx 1800, loss is -0.9996259808540344\n",
      "Our model is testing...\n",
      "2 accuracy is 0.9819\n",
      "Our model is training...\n",
      "epoch 3, batch_idx 0, loss is -0.9605104327201843\n",
      "epoch 3, batch_idx 100, loss is -0.9989392161369324\n",
      "epoch 3, batch_idx 200, loss is -0.9995254874229431\n",
      "epoch 3, batch_idx 300, loss is -0.9671642780303955\n",
      "epoch 3, batch_idx 400, loss is -0.9908308386802673\n",
      "epoch 3, batch_idx 500, loss is -0.9930112361907959\n",
      "epoch 3, batch_idx 600, loss is -0.958060622215271\n",
      "epoch 3, batch_idx 700, loss is -0.9692677855491638\n",
      "epoch 3, batch_idx 800, loss is -0.9988077878952026\n",
      "epoch 3, batch_idx 900, loss is -0.9912542104721069\n",
      "epoch 3, batch_idx 1000, loss is -0.9588019251823425\n",
      "epoch 3, batch_idx 1100, loss is -0.9638141393661499\n",
      "epoch 3, batch_idx 1200, loss is -0.9963129758834839\n",
      "epoch 3, batch_idx 1300, loss is -0.9798476099967957\n",
      "epoch 3, batch_idx 1400, loss is -0.9916937351226807\n",
      "epoch 3, batch_idx 1500, loss is -0.9747432470321655\n",
      "epoch 3, batch_idx 1600, loss is -0.9985617399215698\n",
      "epoch 3, batch_idx 1700, loss is -0.99482262134552\n",
      "epoch 3, batch_idx 1800, loss is -0.998688280582428\n",
      "Our model is testing...\n",
      "3 accuracy is 0.9836\n",
      "Our model is training...\n",
      "epoch 4, batch_idx 0, loss is -0.9981441497802734\n",
      "epoch 4, batch_idx 100, loss is -0.9837119579315186\n",
      "epoch 4, batch_idx 200, loss is -0.9981700778007507\n",
      "epoch 4, batch_idx 300, loss is -0.997156023979187\n",
      "epoch 4, batch_idx 400, loss is -0.9997901916503906\n",
      "epoch 4, batch_idx 500, loss is -0.974221408367157\n",
      "epoch 4, batch_idx 600, loss is -0.9963328838348389\n",
      "epoch 4, batch_idx 700, loss is -0.9924343228340149\n",
      "epoch 4, batch_idx 800, loss is -0.999358594417572\n",
      "epoch 4, batch_idx 900, loss is -0.9810535311698914\n",
      "epoch 4, batch_idx 1000, loss is -0.9950224757194519\n",
      "epoch 4, batch_idx 1100, loss is -0.9854857921600342\n",
      "epoch 4, batch_idx 1200, loss is -0.9949756264686584\n",
      "epoch 4, batch_idx 1300, loss is -0.9982523322105408\n",
      "epoch 4, batch_idx 1400, loss is -0.9987291097640991\n",
      "epoch 4, batch_idx 1500, loss is -0.992685079574585\n",
      "epoch 4, batch_idx 1600, loss is -0.9992663264274597\n",
      "epoch 4, batch_idx 1700, loss is -0.9982466101646423\n",
      "epoch 4, batch_idx 1800, loss is -0.9869450926780701\n",
      "Our model is testing...\n",
      "4 accuracy is 0.9859\n",
      "Our model is training...\n",
      "epoch 5, batch_idx 0, loss is -0.9976473450660706\n",
      "epoch 5, batch_idx 100, loss is -0.9967198967933655\n",
      "epoch 5, batch_idx 200, loss is -0.9809995293617249\n",
      "epoch 5, batch_idx 300, loss is -0.9676981568336487\n",
      "epoch 5, batch_idx 400, loss is -0.9865506887435913\n",
      "epoch 5, batch_idx 500, loss is -0.9956441521644592\n",
      "epoch 5, batch_idx 600, loss is -0.9985033273696899\n",
      "epoch 5, batch_idx 700, loss is -0.9815583229064941\n",
      "epoch 5, batch_idx 800, loss is -0.9757252335548401\n",
      "epoch 5, batch_idx 900, loss is -0.9990965127944946\n",
      "epoch 5, batch_idx 1000, loss is -0.9996317028999329\n",
      "epoch 5, batch_idx 1100, loss is -0.9878556728363037\n",
      "epoch 5, batch_idx 1200, loss is -0.999351441860199\n",
      "epoch 5, batch_idx 1300, loss is -0.9690593481063843\n",
      "epoch 5, batch_idx 1400, loss is -0.9944730997085571\n",
      "epoch 5, batch_idx 1500, loss is -0.9686017632484436\n",
      "epoch 5, batch_idx 1600, loss is -0.9501621723175049\n",
      "epoch 5, batch_idx 1700, loss is -0.9855477213859558\n",
      "epoch 5, batch_idx 1800, loss is -0.9995900988578796\n",
      "Our model is testing...\n",
      "5 accuracy is 0.9878\n",
      "Our model is training...\n",
      "epoch 6, batch_idx 0, loss is -0.9669849276542664\n",
      "epoch 6, batch_idx 100, loss is -0.9673177599906921\n",
      "epoch 6, batch_idx 200, loss is -0.9997802376747131\n",
      "epoch 6, batch_idx 300, loss is -0.9999841451644897\n",
      "epoch 6, batch_idx 400, loss is -0.9603909850120544\n",
      "epoch 6, batch_idx 500, loss is -0.9966672658920288\n",
      "epoch 6, batch_idx 600, loss is -0.998325526714325\n",
      "epoch 6, batch_idx 700, loss is -0.9598220586776733\n",
      "epoch 6, batch_idx 800, loss is -0.9998152256011963\n",
      "epoch 6, batch_idx 900, loss is -0.9994434714317322\n",
      "epoch 6, batch_idx 1000, loss is -0.99985271692276\n",
      "epoch 6, batch_idx 1100, loss is -0.9844043254852295\n",
      "epoch 6, batch_idx 1200, loss is -0.9681126475334167\n",
      "epoch 6, batch_idx 1300, loss is -0.9998151063919067\n",
      "epoch 6, batch_idx 1400, loss is -0.9758848547935486\n",
      "epoch 6, batch_idx 1500, loss is -0.9850495457649231\n",
      "epoch 6, batch_idx 1600, loss is -0.9996815323829651\n",
      "epoch 6, batch_idx 1700, loss is -0.9686345458030701\n",
      "epoch 6, batch_idx 1800, loss is -0.9998122453689575\n",
      "Our model is testing...\n",
      "6 accuracy is 0.9887\n",
      "Our model is training...\n",
      "epoch 7, batch_idx 0, loss is -0.9931249022483826\n",
      "epoch 7, batch_idx 100, loss is -0.9871790409088135\n",
      "epoch 7, batch_idx 200, loss is -0.9995097517967224\n",
      "epoch 7, batch_idx 300, loss is -0.9394479393959045\n",
      "epoch 7, batch_idx 400, loss is -0.968522846698761\n",
      "epoch 7, batch_idx 500, loss is -0.9982525110244751\n",
      "epoch 7, batch_idx 600, loss is -0.936480700969696\n",
      "epoch 7, batch_idx 700, loss is -0.9974416494369507\n",
      "epoch 7, batch_idx 800, loss is -0.9843741655349731\n",
      "epoch 7, batch_idx 900, loss is -0.940837562084198\n",
      "epoch 7, batch_idx 1000, loss is -0.947750449180603\n",
      "epoch 7, batch_idx 1100, loss is -0.9987543821334839\n",
      "epoch 7, batch_idx 1200, loss is -0.9998552203178406\n",
      "epoch 7, batch_idx 1300, loss is -0.9701576828956604\n",
      "epoch 7, batch_idx 1400, loss is -0.9989286065101624\n",
      "epoch 7, batch_idx 1500, loss is -0.9488961100578308\n",
      "epoch 7, batch_idx 1600, loss is -0.999658465385437\n",
      "epoch 7, batch_idx 1700, loss is -0.9851388335227966\n",
      "epoch 7, batch_idx 1800, loss is -0.9897971153259277\n",
      "Our model is testing...\n",
      "7 accuracy is 0.9883\n",
      "Our model is training...\n",
      "epoch 8, batch_idx 0, loss is -0.9963890314102173\n",
      "epoch 8, batch_idx 100, loss is -0.9685001969337463\n",
      "epoch 8, batch_idx 200, loss is -0.9993377923965454\n",
      "epoch 8, batch_idx 300, loss is -0.9971111416816711\n",
      "epoch 8, batch_idx 400, loss is -0.9985175728797913\n",
      "epoch 8, batch_idx 500, loss is -0.9743646383285522\n",
      "epoch 8, batch_idx 600, loss is -0.9677053689956665\n",
      "epoch 8, batch_idx 700, loss is -0.9977782964706421\n",
      "epoch 8, batch_idx 800, loss is -0.9999101161956787\n",
      "epoch 8, batch_idx 900, loss is -0.9840996265411377\n",
      "epoch 8, batch_idx 1000, loss is -0.9997073411941528\n",
      "epoch 8, batch_idx 1100, loss is -0.9985063672065735\n",
      "epoch 8, batch_idx 1200, loss is -0.9996318817138672\n",
      "epoch 8, batch_idx 1300, loss is -0.9754151105880737\n",
      "epoch 8, batch_idx 1400, loss is -0.9789677858352661\n",
      "epoch 8, batch_idx 1500, loss is -0.9994964003562927\n",
      "epoch 8, batch_idx 1600, loss is -0.9572563767433167\n",
      "epoch 8, batch_idx 1700, loss is -0.9719085693359375\n",
      "epoch 8, batch_idx 1800, loss is -0.9999659657478333\n",
      "Our model is testing...\n",
      "8 accuracy is 0.9881\n",
      "Our model is training...\n",
      "epoch 9, batch_idx 0, loss is -0.9623306393623352\n",
      "epoch 9, batch_idx 100, loss is -0.998969316482544\n",
      "epoch 9, batch_idx 200, loss is -0.9983500242233276\n",
      "epoch 9, batch_idx 300, loss is -0.9988002181053162\n",
      "epoch 9, batch_idx 400, loss is -0.9984480738639832\n",
      "epoch 9, batch_idx 500, loss is -0.9993720650672913\n",
      "epoch 9, batch_idx 600, loss is -0.9999121427536011\n",
      "epoch 9, batch_idx 700, loss is -0.986352801322937\n",
      "epoch 9, batch_idx 800, loss is -0.9999895095825195\n",
      "epoch 9, batch_idx 900, loss is -0.9831376671791077\n",
      "epoch 9, batch_idx 1000, loss is -0.9996228814125061\n",
      "epoch 9, batch_idx 1100, loss is -0.9994103312492371\n",
      "epoch 9, batch_idx 1200, loss is -0.9698047637939453\n",
      "epoch 9, batch_idx 1300, loss is -0.9278378486633301\n",
      "epoch 9, batch_idx 1400, loss is -0.9594523310661316\n",
      "epoch 9, batch_idx 1500, loss is -0.9843769073486328\n",
      "epoch 9, batch_idx 1600, loss is -0.9691791534423828\n",
      "epoch 9, batch_idx 1700, loss is -0.9995538592338562\n",
      "epoch 9, batch_idx 1800, loss is -0.9962438344955444\n",
      "Our model is testing...\n",
      "9 accuracy is 0.9901\n",
      "Our model is training...\n",
      "epoch 10, batch_idx 0, loss is -0.988583505153656\n",
      "epoch 10, batch_idx 100, loss is -0.9985616207122803\n",
      "epoch 10, batch_idx 200, loss is -0.999742329120636\n",
      "epoch 10, batch_idx 300, loss is -0.9777066111564636\n",
      "epoch 10, batch_idx 400, loss is -0.9693377614021301\n",
      "epoch 10, batch_idx 500, loss is -0.973340630531311\n",
      "epoch 10, batch_idx 600, loss is -0.9450945854187012\n",
      "epoch 10, batch_idx 700, loss is -0.993035078048706\n",
      "epoch 10, batch_idx 800, loss is -0.9982297420501709\n",
      "epoch 10, batch_idx 900, loss is -0.9991607069969177\n",
      "epoch 10, batch_idx 1000, loss is -0.9897211194038391\n",
      "epoch 10, batch_idx 1100, loss is -0.9993129968643188\n",
      "epoch 10, batch_idx 1200, loss is -0.9687332510948181\n",
      "epoch 10, batch_idx 1300, loss is -0.9865573048591614\n",
      "epoch 10, batch_idx 1400, loss is -0.999982476234436\n",
      "epoch 10, batch_idx 1500, loss is -0.9999328851699829\n",
      "epoch 10, batch_idx 1600, loss is -0.9999899864196777\n",
      "epoch 10, batch_idx 1700, loss is -0.9992405772209167\n",
      "epoch 10, batch_idx 1800, loss is -0.9918351173400879\n",
      "Our model is testing...\n",
      "10 accuracy is 0.9912\n",
      "Our model is training...\n",
      "epoch 11, batch_idx 0, loss is -0.9726796746253967\n",
      "epoch 11, batch_idx 100, loss is -0.9999045133590698\n",
      "epoch 11, batch_idx 200, loss is -0.9952192306518555\n",
      "epoch 11, batch_idx 300, loss is -0.999988853931427\n",
      "epoch 11, batch_idx 400, loss is -0.9357300400733948\n",
      "epoch 11, batch_idx 500, loss is -0.9735947847366333\n",
      "epoch 11, batch_idx 600, loss is -0.9705310463905334\n",
      "epoch 11, batch_idx 700, loss is -0.9999714493751526\n",
      "epoch 11, batch_idx 800, loss is -0.9688368439674377\n",
      "epoch 11, batch_idx 900, loss is -0.9996184706687927\n",
      "epoch 11, batch_idx 1000, loss is -0.9617586135864258\n",
      "epoch 11, batch_idx 1100, loss is -0.9964526295661926\n",
      "epoch 11, batch_idx 1200, loss is -0.9940042495727539\n",
      "epoch 11, batch_idx 1300, loss is -0.9999951124191284\n",
      "epoch 11, batch_idx 1400, loss is -0.999976634979248\n",
      "epoch 11, batch_idx 1500, loss is -0.9963542819023132\n",
      "epoch 11, batch_idx 1600, loss is -0.9991398453712463\n",
      "epoch 11, batch_idx 1700, loss is -0.9701389670372009\n",
      "epoch 11, batch_idx 1800, loss is -0.999849796295166\n",
      "Our model is testing...\n",
      "11 accuracy is 0.9891\n",
      "Our model is training...\n",
      "epoch 12, batch_idx 0, loss is -0.9985173344612122\n",
      "epoch 12, batch_idx 100, loss is -0.9999874234199524\n",
      "epoch 12, batch_idx 200, loss is -0.9936494827270508\n",
      "epoch 12, batch_idx 300, loss is -0.9993240237236023\n",
      "epoch 12, batch_idx 400, loss is -0.9914690852165222\n",
      "epoch 12, batch_idx 500, loss is -0.9999927878379822\n",
      "epoch 12, batch_idx 600, loss is -0.9989109635353088\n",
      "epoch 12, batch_idx 700, loss is -0.9584984183311462\n",
      "epoch 12, batch_idx 800, loss is -0.9998006820678711\n",
      "epoch 12, batch_idx 900, loss is -0.9995583295822144\n",
      "epoch 12, batch_idx 1000, loss is -0.9686960577964783\n",
      "epoch 12, batch_idx 1100, loss is -0.9999032020568848\n",
      "epoch 12, batch_idx 1200, loss is -0.964264452457428\n",
      "epoch 12, batch_idx 1300, loss is -0.9987733960151672\n",
      "epoch 12, batch_idx 1400, loss is -0.9987330436706543\n",
      "epoch 12, batch_idx 1500, loss is -0.9399140477180481\n",
      "epoch 12, batch_idx 1600, loss is -0.9859393239021301\n",
      "epoch 12, batch_idx 1700, loss is -0.9984967708587646\n",
      "epoch 12, batch_idx 1800, loss is -0.9988158941268921\n",
      "Our model is testing...\n",
      "12 accuracy is 0.9896\n",
      "Our model is training...\n",
      "epoch 13, batch_idx 0, loss is -0.9999391436576843\n",
      "epoch 13, batch_idx 100, loss is -0.9996042847633362\n",
      "epoch 13, batch_idx 200, loss is -0.9838681221008301\n",
      "epoch 13, batch_idx 300, loss is -0.9728756546974182\n",
      "epoch 13, batch_idx 400, loss is -0.9852699637413025\n",
      "epoch 13, batch_idx 500, loss is -0.9985656142234802\n",
      "epoch 13, batch_idx 600, loss is -0.9986456036567688\n",
      "epoch 13, batch_idx 700, loss is -0.9890931844711304\n",
      "epoch 13, batch_idx 800, loss is -0.9980076551437378\n",
      "epoch 13, batch_idx 900, loss is -0.9999798536300659\n",
      "epoch 13, batch_idx 1000, loss is -0.9994571805000305\n",
      "epoch 13, batch_idx 1100, loss is -0.9903234243392944\n",
      "epoch 13, batch_idx 1200, loss is -0.9852517247200012\n",
      "epoch 13, batch_idx 1300, loss is -0.9758502840995789\n",
      "epoch 13, batch_idx 1400, loss is -0.999008059501648\n",
      "epoch 13, batch_idx 1500, loss is -0.9976194500923157\n",
      "epoch 13, batch_idx 1600, loss is -0.9778690934181213\n",
      "epoch 13, batch_idx 1700, loss is -0.9999895095825195\n",
      "epoch 13, batch_idx 1800, loss is -0.9999554753303528\n",
      "Our model is testing...\n",
      "13 accuracy is 0.991\n",
      "Our model is training...\n",
      "epoch 14, batch_idx 0, loss is -0.9971461296081543\n",
      "epoch 14, batch_idx 100, loss is -0.9880149364471436\n",
      "epoch 14, batch_idx 200, loss is -0.9968639016151428\n",
      "epoch 14, batch_idx 300, loss is -0.9983558654785156\n",
      "epoch 14, batch_idx 400, loss is -0.9879692792892456\n",
      "epoch 14, batch_idx 500, loss is -0.9706995487213135\n",
      "epoch 14, batch_idx 600, loss is -0.9841099381446838\n",
      "epoch 14, batch_idx 700, loss is -0.9973044991493225\n",
      "epoch 14, batch_idx 800, loss is -0.9532136917114258\n",
      "epoch 14, batch_idx 900, loss is -0.9688058495521545\n",
      "epoch 14, batch_idx 1000, loss is -0.9995869398117065\n",
      "epoch 14, batch_idx 1100, loss is -0.9968559741973877\n",
      "epoch 14, batch_idx 1200, loss is -0.9999972581863403\n",
      "epoch 14, batch_idx 1300, loss is -0.9873180985450745\n",
      "epoch 14, batch_idx 1400, loss is -0.983832597732544\n",
      "epoch 14, batch_idx 1500, loss is -0.9999821186065674\n",
      "epoch 14, batch_idx 1600, loss is -0.9999934434890747\n",
      "epoch 14, batch_idx 1700, loss is -0.9692386984825134\n",
      "epoch 14, batch_idx 1800, loss is -0.9792450070381165\n",
      "Our model is testing...\n",
      "14 accuracy is 0.9903\n",
      "Our model is training...\n",
      "epoch 15, batch_idx 0, loss is -0.9943588376045227\n",
      "epoch 15, batch_idx 100, loss is -0.9713889360427856\n",
      "epoch 15, batch_idx 200, loss is -0.9987279176712036\n",
      "epoch 15, batch_idx 300, loss is -0.9999300241470337\n",
      "epoch 15, batch_idx 400, loss is -0.999995768070221\n",
      "epoch 15, batch_idx 500, loss is -0.9969666600227356\n",
      "epoch 15, batch_idx 600, loss is -0.982505738735199\n",
      "epoch 15, batch_idx 700, loss is -0.9999435544013977\n",
      "epoch 15, batch_idx 800, loss is -0.9936066269874573\n",
      "epoch 15, batch_idx 900, loss is -0.9966006278991699\n",
      "epoch 15, batch_idx 1000, loss is -0.9996383786201477\n",
      "epoch 15, batch_idx 1100, loss is -0.9998897314071655\n",
      "epoch 15, batch_idx 1200, loss is -0.9999879598617554\n",
      "epoch 15, batch_idx 1300, loss is -0.9998449683189392\n",
      "epoch 15, batch_idx 1400, loss is -0.9672060608863831\n",
      "epoch 15, batch_idx 1500, loss is -0.9747105240821838\n",
      "epoch 15, batch_idx 1600, loss is -0.968203604221344\n",
      "epoch 15, batch_idx 1700, loss is -0.9824663996696472\n",
      "epoch 15, batch_idx 1800, loss is -0.9887657761573792\n",
      "Our model is testing...\n",
      "15 accuracy is 0.9912\n",
      "Our model is training...\n",
      "epoch 16, batch_idx 0, loss is -0.9996933937072754\n",
      "epoch 16, batch_idx 100, loss is -0.9687840342521667\n",
      "epoch 16, batch_idx 200, loss is -0.9964776039123535\n",
      "epoch 16, batch_idx 300, loss is -0.995711624622345\n",
      "epoch 16, batch_idx 400, loss is -0.9998185634613037\n",
      "epoch 16, batch_idx 500, loss is -0.9620330929756165\n",
      "epoch 16, batch_idx 600, loss is -0.999565064907074\n",
      "epoch 16, batch_idx 700, loss is -0.9999825954437256\n",
      "epoch 16, batch_idx 800, loss is -0.9864740371704102\n",
      "epoch 16, batch_idx 900, loss is -0.999327540397644\n",
      "epoch 16, batch_idx 1000, loss is -0.9982041716575623\n",
      "epoch 16, batch_idx 1100, loss is -0.9999387860298157\n",
      "epoch 16, batch_idx 1200, loss is -0.9899615049362183\n",
      "epoch 16, batch_idx 1300, loss is -0.9763906002044678\n",
      "epoch 16, batch_idx 1400, loss is -0.999907910823822\n",
      "epoch 16, batch_idx 1500, loss is -0.9970796704292297\n",
      "epoch 16, batch_idx 1600, loss is -0.9999619722366333\n",
      "epoch 16, batch_idx 1700, loss is -0.9851768016815186\n",
      "epoch 16, batch_idx 1800, loss is -0.9932771921157837\n",
      "Our model is testing...\n",
      "16 accuracy is 0.9906\n",
      "Our model is training...\n",
      "epoch 17, batch_idx 0, loss is -0.9989176988601685\n",
      "epoch 17, batch_idx 100, loss is -0.9933602809906006\n",
      "epoch 17, batch_idx 200, loss is -0.9999909996986389\n",
      "epoch 17, batch_idx 300, loss is -0.9999984502792358\n",
      "epoch 17, batch_idx 400, loss is -0.9987686276435852\n",
      "epoch 17, batch_idx 500, loss is -0.9999275803565979\n",
      "epoch 17, batch_idx 600, loss is -0.9781962633132935\n",
      "epoch 17, batch_idx 700, loss is -0.9998905062675476\n",
      "epoch 17, batch_idx 800, loss is -0.9954639673233032\n",
      "epoch 17, batch_idx 900, loss is -0.9838147163391113\n",
      "epoch 17, batch_idx 1000, loss is -0.9970288276672363\n",
      "epoch 17, batch_idx 1100, loss is -0.9974343776702881\n",
      "epoch 17, batch_idx 1200, loss is -0.9920145869255066\n",
      "epoch 17, batch_idx 1300, loss is -0.9999929070472717\n",
      "epoch 17, batch_idx 1400, loss is -0.9787502288818359\n",
      "epoch 17, batch_idx 1500, loss is -0.9640005826950073\n",
      "epoch 17, batch_idx 1600, loss is -0.9662447571754456\n",
      "epoch 17, batch_idx 1700, loss is -0.999600887298584\n",
      "epoch 17, batch_idx 1800, loss is -0.9796076416969299\n",
      "Our model is testing...\n",
      "17 accuracy is 0.9921\n",
      "Our model is training...\n",
      "epoch 18, batch_idx 0, loss is -0.9995704889297485\n",
      "epoch 18, batch_idx 100, loss is -0.9687484502792358\n",
      "epoch 18, batch_idx 200, loss is -0.9939166307449341\n",
      "epoch 18, batch_idx 300, loss is -0.9705477356910706\n",
      "epoch 18, batch_idx 400, loss is -0.9528570771217346\n",
      "epoch 18, batch_idx 500, loss is -0.9999954104423523\n",
      "epoch 18, batch_idx 600, loss is -0.9994919896125793\n",
      "epoch 18, batch_idx 700, loss is -0.9999184608459473\n",
      "epoch 18, batch_idx 800, loss is -0.9686766862869263\n",
      "epoch 18, batch_idx 900, loss is -0.9981977343559265\n",
      "epoch 18, batch_idx 1000, loss is -0.9999355673789978\n",
      "epoch 18, batch_idx 1100, loss is -0.9871901273727417\n",
      "epoch 18, batch_idx 1200, loss is -0.9998051524162292\n",
      "epoch 18, batch_idx 1300, loss is -0.9998906850814819\n",
      "epoch 18, batch_idx 1400, loss is -0.9999953508377075\n",
      "epoch 18, batch_idx 1500, loss is -0.9999735951423645\n",
      "epoch 18, batch_idx 1600, loss is -0.9686613082885742\n",
      "epoch 18, batch_idx 1700, loss is -0.9999983906745911\n",
      "epoch 18, batch_idx 1800, loss is -0.9987807869911194\n",
      "Our model is testing...\n",
      "18 accuracy is 0.9915\n",
      "Our model is training...\n",
      "epoch 19, batch_idx 0, loss is -0.9999856352806091\n",
      "epoch 19, batch_idx 100, loss is -0.9576899409294128\n",
      "epoch 19, batch_idx 200, loss is -0.9993539452552795\n",
      "epoch 19, batch_idx 300, loss is -0.9999985694885254\n",
      "epoch 19, batch_idx 400, loss is -0.9999976754188538\n",
      "epoch 19, batch_idx 500, loss is -0.9995955228805542\n",
      "epoch 19, batch_idx 600, loss is -0.9688509106636047\n",
      "epoch 19, batch_idx 700, loss is -0.9981798529624939\n",
      "epoch 19, batch_idx 800, loss is -0.9748876690864563\n",
      "epoch 19, batch_idx 900, loss is -0.993457019329071\n",
      "epoch 19, batch_idx 1000, loss is -0.9995424151420593\n",
      "epoch 19, batch_idx 1100, loss is -0.9765697121620178\n",
      "epoch 19, batch_idx 1200, loss is -0.999418318271637\n",
      "epoch 19, batch_idx 1300, loss is -0.9990447163581848\n",
      "epoch 19, batch_idx 1400, loss is -0.9999985098838806\n",
      "epoch 19, batch_idx 1500, loss is -0.9999032616615295\n",
      "epoch 19, batch_idx 1600, loss is -0.9995667934417725\n",
      "epoch 19, batch_idx 1700, loss is -0.9999992251396179\n",
      "epoch 19, batch_idx 1800, loss is -0.996748685836792\n",
      "Our model is testing...\n",
      "19 accuracy is 0.991\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    epochs = 20\n",
    "    model = Net()\n",
    "    model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    for epoch in range(epochs):\n",
    "        train_loop(epoch, model)\n",
    "        test_loop(epoch, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0bb0ea-93eb-42dd-b741-739529abc22a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dalle2",
   "language": "python",
   "name": "dalle2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
